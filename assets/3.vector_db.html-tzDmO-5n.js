import{_ as i,c as a,a as n,o as t}from"./app-CFXp0Idr.js";const l="/all-in-rag/images/3_3_1.webp",e={};function h(p,s){return t(),a("div",null,[...s[0]||(s[0]=[n('<h2 id="一、向量数据库的作用" tabindex="-1"><a class="header-anchor" href="#一、向量数据库的作用"><span>一、向量数据库的作用</span></a></h2><p>在前面我们学习了如何使用嵌入模型将文本、图像等非结构化数据转换为高维向量。这些向量是 RAG 系统能够进行语义理解的基础。然而，当向量数量从几百个增长到数百万甚至数十亿时，一个核心问题随之而来：<strong>如何快速、准确地从海量向量中找到与用户查询最相似的那几个？</strong></p><h3 id="_1-1-向量数据库主要功能" tabindex="-1"><a class="header-anchor" href="#_1-1-向量数据库主要功能"><span>1.1 向量数据库主要功能</span></a></h3><p>向量数据库的核心价值在于其高效处理海量高维向量的能力。其主要功能可以概括为以下几点：</p><ol><li><strong>高效的相似性搜索</strong>：这是向量数据库最重要的功能。它利用专门的索引技术（如 HNSW, IVF），能够在数十亿级别的向量中实现毫秒级的近似最近邻（ANN）查询，快速找到与给定查询最相似的数据。</li><li><strong>高维数据存储与管理</strong>：专门为存储高维向量（通常维度成百上千）而优化，支持对向量数据进行增、删、改、查等基本操作。</li><li><strong>丰富的查询能力</strong>：除了基本的相似性搜索，还支持按标量字段过滤查询（例如，在搜索相似图片的同时，指定<code>年份 &gt; 2023</code>）、范围查询和聚类分析等，满足复杂业务需求。</li><li><strong>可扩展与高可用</strong>：现代向量数据库通常采用分布式架构，具备良好的水平扩展能力和容错性，能够通过增加节点来应对数据量的增长，并确保服务的稳定可靠。</li><li><strong>数据与模型生态集成</strong>：与主流的 AI 框架（如 LangChain, LlamaIndex）和机器学习工作流无缝集成，简化了从模型训练到向量检索的应用开发流程。</li></ol><h3 id="_1-2-向量数据库-vs-传统数据库" tabindex="-1"><a class="header-anchor" href="#_1-2-向量数据库-vs-传统数据库"><span>1.2 向量数据库 vs 传统数据库</span></a></h3><p>传统的数据库（如 MySQL）擅长处理结构化数据的精确匹配查询（例如，<code>WHERE age = 25</code>），但它们并非为处理高维向量的相似性搜索而设计的。在庞大的向量集合中进行暴力、线性的相似度计算，其计算成本和时间延迟无法接受。<strong>向量数据库 (Vector Database)</strong> 很好的解决了这一问题，它是一种专门设计用于高效存储、管理和查询高维向量的数据库系统。在 RAG 流程中，它扮演着“知识库”的角色，是连接数据与大语言模型的关键桥梁。</p><p>向量数据库与传统数据库的主要差异如下：</p><table><thead><tr><th style="text-align:left;"><strong>维度</strong></th><th style="text-align:left;"><strong>向量数据库</strong></th><th style="text-align:left;"><strong>传统数据库 (RDBMS)</strong></th></tr></thead><tbody><tr><td style="text-align:left;"><strong>核心数据类型</strong></td><td style="text-align:left;">高维向量 (Embeddings)</td><td style="text-align:left;">结构化数据 (文本、数字、日期)</td></tr><tr><td style="text-align:left;"><strong>查询方式</strong></td><td style="text-align:left;"><strong>相似性搜索</strong> (ANN)</td><td style="text-align:left;"><strong>精确匹配</strong></td></tr><tr><td style="text-align:left;"><strong>索引机制</strong></td><td style="text-align:left;">HNSW, IVF, LSH 等 ANN 索引</td><td style="text-align:left;">B-Tree, Hash Index</td></tr><tr><td style="text-align:left;"><strong>主要应用场景</strong></td><td style="text-align:left;">AI 应用、RAG、推荐系统、图像/语音识别</td><td style="text-align:left;">业务系统 (ERP, CRM)、金融交易、数据报表</td></tr><tr><td style="text-align:left;"><strong>数据规模</strong></td><td style="text-align:left;">轻松应对千亿级向量</td><td style="text-align:left;">通常在千万到亿级行数据，更大规模需复杂分库分表</td></tr><tr><td style="text-align:left;"><strong>性能特点</strong></td><td style="text-align:left;">高维数据检索性能极高，计算密集型</td><td style="text-align:left;">结构化数据查询快，高维数据查询性能呈指数级下降</td></tr><tr><td style="text-align:left;"><strong>一致性</strong></td><td style="text-align:left;">通常为最终一致性</td><td style="text-align:left;">强一致性 (ACID 事务)</td></tr></tbody></table><p>向量数据库和传统数据库并非相互替代的关系，而是<strong>互补关系</strong>。在构建现代 AI 应用时，通常会将两者结合使用：利用传统数据库存储业务元数据和结构化信息，而向量数据库则专门负责处理和检索由 AI 模型产生的海量向量数据。</p><h2 id="二、工作原理" tabindex="-1"><a class="header-anchor" href="#二、工作原理"><span>二、工作原理</span></a></h2><p>向量数据库的核心是高效处理高维向量的相似性搜索。向量是一组有序的数值，可以表示文本、图像、音频等复杂数据的特征或属性。在 RAG 系统中，向量一般通过嵌入模型将原始数据转换为高维向量表示，比如上一节的图文示例。</p><p>向量数据库通常采用四层架构，通过以下技术手段实现高效相似性搜索：</p><ol><li><strong>存储层</strong>：存储向量数据和元数据，优化存储效率，支持分布式存储</li><li><strong>索引层</strong>：维护索引算法（HNSW、LSH、PQ等），创建和优化索引，支持索引调整</li><li><strong>查询层</strong>：处理查询请求，支持混合查询，实现查询优化</li><li><strong>服务层</strong>：管理客户端连接，提供监控和日志，实现安全管理</li></ol><p>主要技术手段包括：</p><ul><li><strong>基于树的方法</strong>：如 Annoy 使用的随机投影树，通过树形结构实现对数复杂度的搜索</li><li><strong>基于哈希的方法</strong>：如 LSH（局部敏感哈希），通过哈希函数将相似向量映射到同一“桶”</li><li><strong>基于图的方法</strong>：如 HNSW（分层可导航小世界图），通过多层邻近图结构实现快速搜索</li><li><strong>基于量化的方法</strong>：如 Faiss 的 IVF 和 PQ，通过聚类和量化压缩向量</li></ul><h2 id="三、主流向量数据库介绍" tabindex="-1"><a class="header-anchor" href="#三、主流向量数据库介绍"><span>三、主流向量数据库介绍</span></a></h2><figure><img src="'+l+`" alt="向量数据库分类图" tabindex="0" loading="lazy"><figcaption>向量数据库分类图</figcaption></figure><p>当前主流的向量数据库产品包括：</p><p><a href="https://www.pinecone.io/" target="_blank" rel="noopener noreferrer"><strong>Pinecone</strong></a>是一款完全托管的向量数据库服务，采用Serverless架构设计。它提供存储计算分离、自动扩展和负载均衡等企业级特性，并保证99.95%的SLA。Pinecone支持多种语言SDK，提供极高可用性和低延迟搜索（&lt;100ms），特别适合企业级生产环境、高并发场景和大规模部署。</p><p><a href="https://github.com/milvus-io/milvus" target="_blank" rel="noopener noreferrer"><strong>Milvus</strong></a>是一款开源的分布式向量数据库，采用分布式架构设计，支持GPU加速和多种索引算法。它能够处理亿级向量检索，提供高性能GPU加速和完善的生态系统。Milvus特别适合大规模部署、高性能要求的场景，以及需要自定义开发的开源项目。</p><p><a href="https://github.com/qdrant/qdrant" target="_blank" rel="noopener noreferrer"><strong>Qdrant</strong></a>是一款高性能的开源向量数据库，采用Rust开发，支持二进制量化技术。它提供多种索引策略和向量混合搜索功能，能够实现极高的性能（RPS&gt;4000）和低延迟搜索。Qdrant特别适合性能敏感应用、高并发场景以及中小规模部署。</p><p><a href="https://github.com/weaviate/weaviate" target="_blank" rel="noopener noreferrer"><strong>Weaviate</strong></a>是一款支持GraphQL的AI集成向量数据库，提供20+AI模块和多模态支持。它采用GraphQL API设计，支持RAG优化，特别适合AI开发、多模态处理和快速开发场景。Weaviate具有活跃的社区支持和易于集成的特点。</p><p><a href="https://github.com/chroma-core/chroma" target="_blank" rel="noopener noreferrer"><strong>Chroma</strong></a>是一款轻量级的开源向量数据库，采用本地优先设计，无依赖。它提供零配置安装、本地运行和低资源消耗等特性，特别适合原型开发、教育培训和小规模应用。Chroma的部署简单，适合快速原型开发。</p><p><strong>选择建议</strong>：</p><ul><li><strong>新手入门/小型项目</strong>：从 <code>ChromaDB</code> 或 <code>FAISS</code> 开始是最佳选择。它们与 LangChain/LlamaIndex 紧密集成，几行代码就能运行，且能满足基本的存储和检索需求。</li><li><strong>生产环境/大规模应用</strong>：当数据量超过百万级，或需要高并发、实时更新、复杂元数据过滤时，应考虑更专业的解决方案，如 <code>Milvus</code>、<code>Weaviate</code> 或云服务 <code>Pinecone</code>。</li></ul><h2 id="四、本地向量存储-以-faiss-为例" tabindex="-1"><a class="header-anchor" href="#四、本地向量存储-以-faiss-为例"><span>四、本地向量存储：以 FAISS 为例</span></a></h2><p>FAISS (Facebook AI Similarity Search) 是一个由 Facebook AI Research 开发的高性能库，专门用于高效的相似性搜索和密集向量聚类。当与 LangChain 结合使用时，它可以作为一个强大的本地向量存储方案，非常适合快速原型设计和中小型应用。</p><p>与 ChromaDB 等数据库不同，FAISS 本质上是一个算法库，它将索引直接保存为本地文件（一个 <code>.faiss</code> 索引文件和一个 <code>.pkl</code> 映射文件），而非运行一个数据库服务。这种方式轻量且高效。</p><h3 id="_4-1-环境准备" tabindex="-1"><a class="header-anchor" href="#_4-1-环境准备"><span>4.1 环境准备</span></a></h3><p>在开始之前，请确保已安装所有必需的库：</p><blockquote><p>当前requirements.txt安装的 <code>faiss-cpu</code> 是 CPU 版本。如果你的机器有 GPU，可以安装 <code>faiss-gpu</code> 以获得更好的性能。</p></blockquote><h3 id="_4-2-基础示例-faiss" tabindex="-1"><a class="header-anchor" href="#_4-2-基础示例-faiss"><span>4.2 基础示例(FAISS)</span></a></h3><p>下面的代码演示了使用 LangChain 和 FAISS 完成一个完整的“创建 -&gt; 保存 -&gt; 加载 -&gt; 查询”流程。</p><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain_community</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">vectorstores </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> FAISS</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain_community</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">embeddings </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> HuggingFaceEmbeddings</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain_core</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">documents </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> Document</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 1. 示例文本和嵌入模型</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">texts </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> [</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">    &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">张三是法外狂徒</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">    &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">FAISS是一个用于高效相似性搜索和密集向量聚类的库。</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">    &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">LangChain是一个用于开发由语言模型驱动的应用程序的框架。</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">]</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">docs </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#999999;--shiki-dark:#666666;"> [</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">Document</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">page_content</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">t</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;"> for</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> t </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">in</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> texts</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">]</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">embeddings </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> HuggingFaceEmbeddings</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">model_name</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">BAAI/bge-small-zh-v1.5</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 2. 创建向量存储并保存到本地</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">vectorstore </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> FAISS</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">from_documents</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">docs</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> embeddings</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">local_faiss_path </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">./faiss_index_store</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">vectorstore</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">save_local</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">local_faiss_path</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">f</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">&quot;FAISS index has been saved to </span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">{</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">local_faiss_path</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">}</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 3. 加载索引并执行查询</span></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 加载时需指定相同的嵌入模型，并允许反序列化</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">loaded_vectorstore </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> FAISS</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">load_local</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    local_faiss_path</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">    embeddings</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span></span>
<span class="line"><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">    allow_dangerous_deserialization</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">True</span></span>
<span class="line"><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 相似性搜索</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">query </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">FAISS是做什么的？</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">results </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> loaded_vectorstore</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">similarity_search</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">query</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> k</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">1</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">f</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">&quot;</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">\\n</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">查询: &#39;</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">{</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">query</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">}</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">&#39;&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">相似度最高的文档:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">for</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> doc </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">in</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> results</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">    print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">f</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">&quot;- </span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">{</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">doc</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">page_content</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">}</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>运行结果与解读</strong>：</p><p>当你运行上述脚本时，会看到类似以下的输出：</p><div class="language-bash line-numbers-mode" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">FAISS</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> index</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> has</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> been</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> saved</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> to</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ./faiss_index_store</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">查询:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">FAISS是做什么的？</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">相似度最高的文档:</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">-</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> FAISS是一个用于高效相似性搜索和密集向量聚类的库。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>索引创建实现细节</strong>： 通过深入 LangChain 源码，可以发现索引创建是一个分层、解耦的过程，主要涉及以下几个方法的嵌套调用：</p><ol><li><p><strong><code>from_documents</code> (封装层)</strong>:</p><ul><li>这是我们直接调用的方法。它的职责很简单：从输入的 <code>Document</code> 对象列表中提取出纯文本内容 (<code>page_content</code>) 和元数据 (<code>metadata</code>)。</li><li>然后，它将这些提取出的信息传递给核心的 <code>from_texts</code> 方法。</li></ul></li><li><p><strong><code>from_texts</code> (向量化入口)</strong>:</p><ul><li>这个方法是面向用户的入口。它接收文本列表，并执行关键的第一步：调用 <code>embedding.embed_documents(texts)</code>，将所有文本批量转换为向量。</li><li>完成向量化后，它并不直接处理索引构建，而是将生成的向量和其他所有信息（文本、元数据等）传递给一个内部的辅助方法 <code>__from</code>。</li></ul></li><li><p><strong><code>__from</code> (构建索引框架)</strong>:</p><ul><li>一个内部方法，负责搭建 FAISS 向量存储的“空框架”。</li><li>它会根据指定的距离策略（默认为 L2 欧氏距离）初始化一个空的 FAISS 索引结构（如 <code>faiss.IndexFlatL2</code>）。</li><li>同时，它也准备好了用于存储文档原文的 <code>docstore</code> 和用于连接 FAISS 索引与文档的 <code>index_to_docstore_id</code> 映射。</li><li>最后，它调用另一个内部方法 <code>__add</code> 来完成数据的填充。</li></ul></li><li><p><strong><code>__add</code> (填充数据)</strong>:</p><ul><li>真正执行数据添加操作的核心。它接收到向量、文本和元数据后，执行以下关键操作： <ul><li><strong>添加向量</strong>: 将向量列表转换为 FAISS 需要的 <code>numpy</code> 数组，并调用 <code>self.index.add(vector)</code> 将其批量添加到 FAISS 索引中。</li><li><strong>存储文档</strong>: 将文本和元数据打包成 <code>Document</code> 对象，存入 <code>docstore</code>。</li><li><strong>建立映射</strong>: 更新 <code>index_to_docstore_id</code> 字典，建立起 FAISS 内部的整数 ID（如 0, 1, 2...）到我们文档唯一 ID 的映射关系。</li></ul></li></ul></li></ol><h2 id="练习" tabindex="-1"><a class="header-anchor" href="#练习"><span>练习</span></a></h2><ol><li>LlamaIndex默认会将数据存储为透明可读的JSON格式，运行<a href="https://github.com/datawhalechina/all-in-rag/blob/main/code/C3/03_llamaindex_vector.py" target="_blank" rel="noopener noreferrer">03_llamaindex_vector.py</a>文件，查看保存的json文件内容。</li><li>新建一个代码文件实现对LlamaIndex存储数据的加载和相似性搜索。</li></ol>`,42)])])}const r=i(e,[["render",h]]),d=JSON.parse('{"path":"/chapter3/3.vector_db.html","title":"第三节 向量数据库","lang":"zh-CN","frontmatter":{"createTime":"2025/09/28 17:32:01","title":"第三节 向量数据库"},"readingTime":{"minutes":9.89,"words":2966},"git":{"createdTime":1751557765000,"updatedTime":1759129919000,"contributors":[{"name":"FutureUnreal","username":"FutureUnreal","email":"42101210307@stu.xpu.edu.cn","commits":11,"avatar":"https://avatars.githubusercontent.com/FutureUnreal?v=4","url":"https://github.com/FutureUnreal"},{"name":"1985312383","username":"1985312383","email":"56398475+1985312383@users.noreply.github.com","commits":1,"avatar":"https://avatars.githubusercontent.com/1985312383?v=4","url":"https://github.com/1985312383"}]},"filePathRelative":"chapter3/3.vector_db.md","headers":[]}');export{r as comp,d as data};
