import{_ as e}from"./1_1_2-DaRHvR2c.js";import{_ as a,c as n,a as r,o}from"./app-CFXp0Idr.js";const s="/all-in-rag/images/1_1.svg",l={};function i(d,t){return o(),n("div",null,[...t[0]||(t[0]=[r('<h2 id="一、什么是rag" tabindex="-1"><a class="header-anchor" href="#一、什么是rag"><span>一、什么是RAG？</span></a></h2><h3 id="_1-1-核心定义" tabindex="-1"><a class="header-anchor" href="#_1-1-核心定义"><span>1.1 核心定义</span></a></h3><p>RAG（Retrieval-Augmented Generation）是一种<strong>融合信息检索与文本生成</strong>的技术范式。其核心逻辑是：在大型语言模型（LLM）生成文本前，先通过检索机制从外部知识库中动态获取相关信息，并将检索结果融入生成过程，从而提升输出的准确性和时效性<sup class="footnote-ref"><a href="#footnote1">[1]</a><a class="footnote-anchor" id="footnote-ref1"></a></sup><sup class="footnote-ref"><a href="#footnote2">[2]</a><a class="footnote-anchor" id="footnote-ref2"></a></sup><sup class="footnote-ref"><a href="#footnote3">[3]</a><a class="footnote-anchor" id="footnote-ref3"></a></sup>。</p><blockquote><p>当然RAG的定义会随着技术的发展而拓展，所以当前定义仅作为基本框架的确立。</p></blockquote><p>💡 <strong>RAG本质</strong>：在LLM生成文本之前，先从<strong>外部知识库</strong>中检索相关信息，作为上下文辅助生成更准确的回答。</p><h3 id="_1-2-技术原理" tabindex="-1"><a class="header-anchor" href="#_1-2-技术原理"><span>1.2 技术原理</span></a></h3><ul><li><strong>双阶段架构</strong>：</li></ul><div align="center"><img src="'+s+'" alt="双阶段" width="800"></div><ul><li><strong>关键组件</strong>： <ol><li><strong>索引（Indexing）</strong> 📑：将非结构化文档（PDF/Word等）分割为片段，通过嵌入模型转换为向量数据。</li><li><strong>检索（Retrieval）</strong> 🔍️：基于查询语义，从向量数据库召回最相关的文档片段（Context）。</li><li><strong>生成（Generation）</strong> ✨：将检索结果作为上下文输入LLM，生成自然语言响应。</li></ol></li></ul><h3 id="_1-3-技术演进分类" tabindex="-1"><a class="header-anchor" href="#_1-3-技术演进分类"><span>1.3 技术演进分类</span></a></h3><p>RAG技术按照复杂度可划分为<sup class="footnote-ref"><a href="#footnote4">[4]</a><a class="footnote-anchor" id="footnote-ref4"></a></sup>：</p><table><thead><tr><th style="text-align:center;"><strong>初级RAG</strong></th><th style="text-align:center;"><strong>高级RAG</strong></th><th style="text-align:center;"><strong>模块化RAG</strong></th></tr></thead><tbody><tr><td style="text-align:center;">基础&quot;索引-检索-生成&quot;流程</td><td style="text-align:center;">增加数据清洗流程</td><td style="text-align:center;">灵活集成搜索引擎</td></tr><tr><td style="text-align:center;">简单文档分块</td><td style="text-align:center;">元数据优化</td><td style="text-align:center;">强化学习优化</td></tr><tr><td style="text-align:center;">基本向量检索机制</td><td style="text-align:center;">多轮检索策略</td><td style="text-align:center;">知识图谱增强</td></tr><tr><td style="text-align:center;">-</td><td style="text-align:center;">提升准确性和效率</td><td style="text-align:center;">支持复杂业务场景</td></tr></tbody></table><figure><img src="'+e+`" alt="分类图" tabindex="0" loading="lazy"><figcaption>分类图</figcaption></figure><h2 id="二、为什么要使用rag" tabindex="-1"><a class="header-anchor" href="#二、为什么要使用rag"><span>二、为什么要使用RAG<sup class="footnote-ref"><a href="#footnote5">[5]</a><a class="footnote-anchor" id="footnote-ref5"></a></sup>？</span></a></h2><h3 id="_2-1-解决llm的核心局限" tabindex="-1"><a class="header-anchor" href="#_2-1-解决llm的核心局限"><span>2.1 解决LLM的核心局限</span></a></h3><table><thead><tr><th>问题</th><th>RAG的解决方案</th></tr></thead><tbody><tr><td><strong>静态知识局限</strong></td><td>实时检索外部知识库，支持动态更新</td></tr><tr><td><strong>幻觉（Hallucination）</strong></td><td>基于检索内容生成，错误率降低</td></tr><tr><td><strong>领域专业性不足</strong></td><td>引入领域特定知识库（如医疗/法律）</td></tr><tr><td><strong>数据隐私风险</strong></td><td>本地化部署知识库，避免敏感数据泄露</td></tr></tbody></table><h3 id="_2-2-关键优势" tabindex="-1"><a class="header-anchor" href="#_2-2-关键优势"><span>2.2 关键优势</span></a></h3><ol><li><strong>准确性提升</strong></li></ol><ul><li>知识基础扩展：补充LLM预训练知识的不足，增强对专业领域的理解</li><li>降低幻觉现象：通过提供具体参考材料，减少无中生有的情况</li><li>可溯源引用：支持引用原始文档，提高输出内容的可信度和说服力</li></ul><ol start="2"><li><strong>实时性保障</strong></li></ol><ul><li>动态知识更新：知识库内容可以独立于模型进行实时更新和维护</li><li>减少时滞性：规避LLM预训练数据截止日期带来的知识时效性问题</li></ul><ol start="3"><li><strong>成本效益</strong></li></ol><ul><li>避免频繁微调：相比反复微调LLM，维护知识库成本更低</li><li>降低推理成本：针对特定领域问题，可使用更小的基础模型配合知识库</li><li>资源消耗优化：减少存储完整知识在模型权重中的计算资源需求</li><li>快速适应变化：新信息或政策更新只需更新知识库，无需重训练模型</li></ul><ol start="4"><li><strong>可扩展性</strong></li></ol><ul><li>多源集成：支持从不同来源和格式的数据中构建统一知识库</li><li>模块化设计：检索组件可独立优化，不影响生成组件</li></ul><h3 id="_2-3-适用场景风险分级" tabindex="-1"><a class="header-anchor" href="#_2-3-适用场景风险分级"><span>2.3 适用场景风险分级</span></a></h3><blockquote><p>以下是RAG技术在不同风险等级场景中的适用性</p></blockquote><table><thead><tr><th style="text-align:center;">风险等级</th><th style="text-align:left;">案例</th><th style="text-align:center;">RAG适用性</th></tr></thead><tbody><tr><td style="text-align:center;"><strong>低风险</strong></td><td style="text-align:left;">翻译/语法检查</td><td style="text-align:center;">高可靠性</td></tr><tr><td style="text-align:center;"><strong>中风险</strong></td><td style="text-align:left;">合同起草/法律咨询</td><td style="text-align:center;">需结合人工审核</td></tr><tr><td style="text-align:center;"><strong>高风险</strong></td><td style="text-align:left;">证据分析/签证决策</td><td style="text-align:center;">需严格质量控制机制</td></tr></tbody></table><h2 id="三、如何上手rag" tabindex="-1"><a class="header-anchor" href="#三、如何上手rag"><span>三、如何上手RAG？</span></a></h2><h3 id="_3-1-基础工具链选择" tabindex="-1"><a class="header-anchor" href="#_3-1-基础工具链选择"><span>3.1 基础工具链选择</span></a></h3><p><strong>开发框架</strong></p><ul><li><strong>LangChain</strong>：提供预置RAG链（如rag_chain），支持快速集成LLM与向量库</li><li><strong>LlamaIndex</strong>：专为知识库索引优化，简化文档分块与嵌入流程</li></ul><p><strong>向量数据库</strong></p><ul><li><strong>Milvus</strong>：开源高性能向量数据库</li><li><strong>FAISS</strong>：轻量级向量搜索库</li><li><strong>Pinecone</strong>：云服务向量数据库</li></ul><h3 id="_3-2-四步构建最小可行系统-mvp" tabindex="-1"><a class="header-anchor" href="#_3-2-四步构建最小可行系统-mvp"><span>3.2 四步构建最小可行系统（MVP）</span></a></h3><ol><li><p><strong>数据准备</strong></p><ul><li>格式支持：PDF、Word、网页文本等</li><li>分块策略：按语义（如段落）或固定长度切分，避免信息碎片化</li></ul></li><li><p><strong>索引构建</strong></p><ul><li>嵌入模型：选取开源模型（如text-embedding-ada-002）或微调领域专用模型</li><li>向量化：将文本分块转换为向量存入数据库</li></ul></li><li><p><strong>检索优化</strong></p><ul><li>混合检索：结合关键词（BM25）与语义搜索（向量相似度）提升召回率</li><li>重排序（Rerank）：用小模型筛选Top-K相关片段（如Cohere Reranker）</li></ul></li><li><p><strong>生成集成</strong></p><ul><li>提示工程：设计模板引导LLM融合检索内容</li><li>LLM选型：GPT、Claude、Ollama等（按成本/性能权衡）</li></ul></li></ol><h3 id="_3-3-新手友好方案" tabindex="-1"><a class="header-anchor" href="#_3-3-新手友好方案"><span>3.3 新手友好方案</span></a></h3><ul><li><strong>LangChain4j Easy RAG</strong>：仅需上传文档，自动处理索引与检索</li><li><strong>FastGPT</strong>：开源知识库平台，可视化配置RAG流程</li><li><strong>GitHub模板</strong>：如&quot;TinyRAG&quot;项目<sup class="footnote-ref"><a href="#footnote6">[6]</a><a class="footnote-anchor" id="footnote-ref6"></a></sup>，提供完整代码</li></ul><h3 id="_3-4-进阶调优方向" tabindex="-1"><a class="header-anchor" href="#_3-4-进阶调优方向"><span>3.4 进阶调优方向</span></a></h3><p><strong>评估指标</strong></p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-"><span class="line"><span>检索质量：上下文相关性（Context Relevance）</span></span>
<span class="line"><span>生成质量：答案忠实度（Faithfulness）、事实准确性</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>性能优化</strong></p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-"><span class="line"><span>索引分层：对高频数据启用缓存机制</span></span>
<span class="line"><span>多模态扩展：支持图像/表格检索</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>RAG技术仍在快速发展中，可以持续关注学术和工业界的最新进展！</p></blockquote><h2 id="参考文献" tabindex="-1"><a class="header-anchor" href="#参考文献"><span>参考文献</span></a></h2><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="footnote1" class="footnote-item"><p><a href="https://www.researchgate.net/publication/391141346_Retrieval-Augmented_Generation_Methods_Applications_and_Challenges" target="_blank" rel="noopener noreferrer">Genesis, J. (2025). <em>Retrieval-Augmented Text Generation: Methods, Challenges, and Applications</em></a>. <a href="#footnote-ref1" class="footnote-backref">↩︎</a></p></li><li id="footnote2" class="footnote-item"><p><a href="https://arxiv.org/abs/2312.10997" target="_blank" rel="noopener noreferrer">Gao et al. (2023). <em>Retrieval-Augmented Generation for Large Language Models: A Survey</em></a>. <a href="#footnote-ref2" class="footnote-backref">↩︎</a></p></li><li id="footnote3" class="footnote-item"><p><a href="https://arxiv.org/abs/2005.11401" target="_blank" rel="noopener noreferrer">Lewis et al. (2020). <em>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</em></a>. <a href="#footnote-ref3" class="footnote-backref">↩︎</a></p></li><li id="footnote4" class="footnote-item"><p><a href="https://arxiv.org/abs/2407.21059" target="_blank" rel="noopener noreferrer">Gao et al. (2024). <em>Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks</em></a>. <a href="#footnote-ref4" class="footnote-backref">↩︎</a></p></li><li id="footnote5" class="footnote-item"><p><a href="https://www.lawdroidmanifesto.com/p/rag-why-does-it-matter-what-is-it" target="_blank" rel="noopener noreferrer"><em>RAG: Why Does It Matter, What Is It, and Does It Guarantee Accuracy?</em></a>. <a href="#footnote-ref5" class="footnote-backref">↩︎</a></p></li><li id="footnote6" class="footnote-item"><p><a href="https://github.com/KMnO4-zx/TinyRAG" target="_blank" rel="noopener noreferrer"><em>TinyRAG: GitHub项目</em></a>. <a href="#footnote-ref6" class="footnote-backref">↩︎</a></p></li></ol></section>`,47)])])}const c=a(l,[["render",i]]),f=JSON.parse('{"path":"/chapter1/1.RAG_intro.html","title":"第一节 RAG简介","lang":"zh-CN","frontmatter":{"createTime":"2025/09/28 17:32:01","title":"第一节 RAG简介"},"readingTime":{"minutes":4.87,"words":1461},"git":{"createdTime":1749130427000,"updatedTime":1759129919000,"contributors":[{"name":"FutureUnreal","username":"FutureUnreal","email":"42101210307@stu.xpu.edu.cn","commits":13,"avatar":"https://avatars.githubusercontent.com/FutureUnreal?v=4","url":"https://github.com/FutureUnreal"},{"name":"1985312383","username":"1985312383","email":"56398475+1985312383@users.noreply.github.com","commits":1,"avatar":"https://avatars.githubusercontent.com/1985312383?v=4","url":"https://github.com/1985312383"}]},"filePathRelative":"chapter1/1.RAG_intro.md","headers":[]}');export{c as comp,f as data};
